{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Brax Problem in EvoX\n",
    "\n",
    "EvoX deeply dives into neuroevolution with Brax.\n",
    "Here we will show an example of solving Brax problem in EvoX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install EvoX and Brax, skip it if you have already installed EvoX\n",
    "from importlib.util import find_spec\n",
    "\n",
    "if find_spec(\"evox\") is None:\n",
    "    %pip install evox\n",
    "\n",
    "if find_spec(\"evox\") is None:\n",
    "    %pip install evox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependent packages or functions in this example\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from evox.algorithms import PSO\n",
    "from evox.problems.neuroevolution.brax import BraxProblem\n",
    "from evox.utils import ParamsAndVector\n",
    "from evox.workflows import EvalMonitor, StdWorkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Brax\n",
    "\n",
    "Brax is a fast and fully differentiable physics engine used for research and development of robotics, human perception, materials science, reinforcement learning, and other simulation-heavy applications. \n",
    "\n",
    "Here we will demonstrate a \"hopper\" environment of Brax. \n",
    "\n",
    "For more information, you can browse the [Github of Brax](https://github.com/google/brax)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design a neural network class\n",
    "\n",
    "To start with, we need to decide which neural network we are about to construct.\n",
    "\n",
    "Here we will give a simple Multilayer Perceptron (MLP) class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an MLP using PyTorch.\n",
    "# This MLP has 3 layers.\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Linear(11, 4), nn.Tanh(), nn.Linear(4, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate a model\n",
    "\n",
    "Through the ``SimpleMLP`` class, we can initiate a MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the model is on the same device, better to be on the GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Reset the random seed\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Initialize the MLP model\n",
    "model = SimpleMLP().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate an adapter\n",
    "\n",
    "An adapter can help us convert the data back-and-forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = ParamsAndVector(dummy_model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an adapter, we can set out to do this Neuroevolution Task.\n",
    "\n",
    "## Set up the running process\n",
    "\n",
    "### Initiate an algorithm and a problem\n",
    "\n",
    "We initiate a PSO algorithm, and the problem is a Brax problem in \"hopper\" environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the population size\n",
    "POP_SIZE = 10\n",
    "\n",
    "# Get the bound of the PSO algorithm\n",
    "model_params = dict(model.named_parameters())\n",
    "pop_center = adapter.to_vector(model_params)\n",
    "lower_bound = pop_center - 1\n",
    "upper_bound = pop_center + 1\n",
    "\n",
    "# Initialize the PSO, and you can also use any other algorithms\n",
    "algorithm = PSO(\n",
    "            pop_size=POP_SIZE,\n",
    "            lb=lower_bound,\n",
    "            ub=upper_bound,\n",
    "            device=device,\n",
    "        )\n",
    "algorithm.setup()\n",
    "\n",
    "# Initialize the Brax problem\n",
    "problem = BraxProblem(\n",
    "            policy=model,\n",
    "            env_name=\"hopper\",\n",
    "            max_episode_length=1000,\n",
    "            num_episodes=3,\n",
    "            pop_size=POP_SIZE,\n",
    "            device=device,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will be using 1000 steps for each episode, and the average reward of 3 episodes will be returned as the fitness value.\n",
    "\n",
    "### Set an monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalMonitor()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set an monitor, and it can record the top 3 best fitnesses\n",
    "pop_monitor = EvalMonitor(\n",
    "            topk=3,\n",
    "            device=device,\n",
    "        )\n",
    "pop_monitor.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate an workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an workflow\n",
    "workflow = StdWorkflow(opt_direction=\"max\")\n",
    "workflow.setup(\n",
    "    algorithm=algorithm,\n",
    "    problem=problem,\n",
    "    solution_transform=adapter,\n",
    "    monitor=pop_monitor,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the workflow\n",
    "\n",
    "Run the workflow and see the magic!\n",
    "\n",
    "```{note}\n",
    "The following block will take around 1 minute to run.\n",
    "The time may vary depending on your hardware.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generation 0:\n",
      "\tTime elapsed:  21.9649(s).\n",
      "\tTop fitness: tensor([-637.1375, -624.4020, -600.7485])\n",
      "\tBest params: {'features.0.weight': tensor([[ 0.6129, -0.9546,  0.3324,  0.0898, -0.4953, -0.0171,  0.1294, -0.2014,\n",
      "         -0.8625, -0.4629,  1.0194],\n",
      "        [-0.8231, -0.1714,  0.6062,  0.5981, -0.6424, -0.8224,  0.6978,  0.5227,\n",
      "          0.7899,  0.6351, -0.9706],\n",
      "        [ 0.1818,  0.0418,  0.4349, -0.2376,  0.9384, -0.0688, -0.5130,  0.3086,\n",
      "          0.0793, -0.7233, -0.2675],\n",
      "        [-0.7382,  0.2115,  0.3164, -0.0696,  0.0377, -0.2678, -1.2471, -0.0779,\n",
      "          0.6473, -0.7199,  0.2839]], grad_fn=<ViewBackward0>), 'features.0.bias': tensor([-0.6246, -0.0321,  0.1846, -0.7549], grad_fn=<ViewBackward0>), 'features.2.weight': tensor([[-0.4736,  0.2928,  0.1783,  1.1226],\n",
      "        [ 0.5829,  0.8406, -0.2133, -1.0378],\n",
      "        [-0.9943, -1.0495, -0.1016, -0.3519]], grad_fn=<ViewBackward0>), 'features.2.bias': tensor([-0.0952,  0.0042, -0.0048], grad_fn=<ViewBackward0>)}\n",
      "In generation 1:\n",
      "\tTime elapsed:  9.3191(s).\n",
      "\tTop fitness: tensor([-840.4749, -669.0715, -649.1846])\n",
      "\tBest params: {'features.0.weight': tensor([[-1.1147,  0.3197,  0.8552,  0.9196, -0.7702, -0.8790,  0.7297,  0.8726,\n",
      "         -0.2595, -0.6112,  0.1389],\n",
      "        [-0.7869,  1.0932,  0.9475,  0.8669,  0.7123, -1.1304, -0.9055,  0.8425,\n",
      "          1.1395,  0.4560, -1.1180],\n",
      "        [ 0.8521,  1.0780, -0.2839, -0.5586, -0.4330,  0.3191, -0.8286, -1.2096,\n",
      "          0.6259,  0.1197, -0.3318],\n",
      "        [-1.1076, -0.9538,  0.8061, -0.0956,  0.0649,  0.7615, -0.7909, -0.4892,\n",
      "         -0.4028, -0.4292, -0.5819]], grad_fn=<ViewBackward0>), 'features.0.bias': tensor([ 0.4799, -0.1172,  0.9511, -1.2620], grad_fn=<ViewBackward0>), 'features.2.weight': tensor([[-0.6161, -0.4764, -0.0197,  0.4302],\n",
      "        [-0.5737,  0.9369,  1.3805, -0.8075],\n",
      "        [-1.3900, -0.7165, -0.1811, -0.5611]], grad_fn=<ViewBackward0>), 'features.2.bias': tensor([-0.2639,  0.1055, -0.8396], grad_fn=<ViewBackward0>)}\n",
      "In generation 2:\n",
      "\tTime elapsed:  9.4047(s).\n",
      "\tTop fitness: tensor([-840.4749, -828.4033, -724.8026])\n",
      "\tBest params: {'features.0.weight': tensor([[-1.1147,  0.3197,  0.8552,  0.9196, -0.7702, -0.8790,  0.7297,  0.8726,\n",
      "         -0.2595, -0.6112,  0.1389],\n",
      "        [-0.7869,  1.0932,  0.9475,  0.8669,  0.7123, -1.1304, -0.9055,  0.8425,\n",
      "          1.1395,  0.4560, -1.1180],\n",
      "        [ 0.8521,  1.0780, -0.2839, -0.5586, -0.4330,  0.3191, -0.8286, -1.2096,\n",
      "          0.6259,  0.1197, -0.3318],\n",
      "        [-1.1076, -0.9538,  0.8061, -0.0956,  0.0649,  0.7615, -0.7909, -0.4892,\n",
      "         -0.4028, -0.4292, -0.5819]], grad_fn=<ViewBackward0>), 'features.0.bias': tensor([ 0.4799, -0.1172,  0.9511, -1.2620], grad_fn=<ViewBackward0>), 'features.2.weight': tensor([[-0.6161, -0.4764, -0.0197,  0.4302],\n",
      "        [-0.5737,  0.9369,  1.3805, -0.8075],\n",
      "        [-1.3900, -0.7165, -0.1811, -0.5611]], grad_fn=<ViewBackward0>), 'features.2.bias': tensor([-0.2639,  0.1055, -0.8396], grad_fn=<ViewBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum number of generations\n",
    "max_generation = 3\n",
    "\n",
    "# Run the workflow\n",
    "for index in range(max_generation):\n",
    "        print(f\"In generation {index}:\")\n",
    "        t = time.time()\n",
    "        workflow.step()\n",
    "        print(f\"\\tTime elapsed: {time.time() - t: .4f}(s).\")\n",
    "        monitor: EvalMonitor = workflow.get_submodule(\"monitor\")\n",
    "        print(f\"\\tTop fitness: {monitor.topk_fitness}\")\n",
    "        best_params = adapter.to_params(monitor.topk_solutions[0])\n",
    "        print(f\"\\tBest params: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The PSO wasn’t specialized for this type of tasks, so its performance limitations here are expected. Here we just show an example.\n",
    "```\n",
    "\n",
    "Hope you can have fun solving Brax problems in EvoX and enjoy your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evoxtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
