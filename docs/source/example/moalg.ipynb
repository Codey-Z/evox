{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Objective Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the Reference Vector Guided Evolutionary Algorithm (**RVEA**) to find the optimal solutions of the **DTLZ2** problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install evox, skip it if you have already installed evox\n",
    "try:\n",
    "    import evox\n",
    "except ImportError:\n",
    "    !pip install --disable-pip-version-check --upgrade -q evox\n",
    "    import evox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.profiler import ProfilerActivity, profile\n",
    "\n",
    "from evox.algorithms import RVEA\n",
    "from evox.core import jit, use_state\n",
    "from evox.metrics import igd\n",
    "from evox.problems.numerical import DTLZ2\n",
    "from evox.workflows import StdWorkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Use GPU to run the code\n",
    "Often, we want to run our code on a GPU because it will run faster. The following code sets the default to run on GPU. Using the CPU is also fine if no device is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU first to run the code.\n",
    "torch.set_default_device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.get_default_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running example: RVEA on DTLZ2 problem\n",
    "The following code is used to set up the DTLZ2 problem and the RVEA algorithm. More information about the problem and algorithm can be found in the corresponding section of the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the problem, algorithm and workflow.\n",
    "prob = DTLZ2(m=3)\n",
    "pf = prob.pf()\n",
    "algo = RVEA(pop_size=100, n_objs=3, lb=-torch.zeros(12), ub=torch.ones(12))\n",
    "workflow = StdWorkflow()\n",
    "workflow.setup(algo, prob)\n",
    "workflow.init_step()\n",
    "\n",
    "# Init the state_step and the jit_state_step\n",
    "state_step = use_state(lambda: workflow.step)\n",
    "state = state_step.init_state()\n",
    "jit_state_step = jit(state_step, trace=True, example_inputs=(state,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this setup in place, we can now start to optimize. We set to let the multi-objective algorithm optimize for 100 steps on this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5292, device='cuda:0')\n",
      "tensor(0.1605, device='cuda:0')\n",
      "tensor(0.0774, device='cuda:0')\n",
      "tensor(0.0614, device='cuda:0')\n",
      "tensor(0.0581, device='cuda:0')\n",
      "tensor(0.0569, device='cuda:0')\n",
      "tensor(0.0556, device='cuda:0')\n",
      "tensor(0.0550, device='cuda:0')\n",
      "tensor(0.0553, device='cuda:0')\n",
      "tensor(0.0545, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Run the workflow for 100 steps\n",
    "t = time.time()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, profile_memory=True) as prof:\n",
    "    for i in range(100):\n",
    "        state = jit_state_step(state)\n",
    "        fit = state[\"self.algorithm.fit\"]\n",
    "        fit = fit[~torch.isnan(fit).any(dim=1)]\n",
    "        if i % 10 == 0:\n",
    "          print(igd(fit, pf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
