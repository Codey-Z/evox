{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Applications\n",
    "\n",
    "EvoX facilitates efficient exploration of complex optimization landscapes, effective tackling of black-box optimization challenges, and deep dives into neuroevolution with Brax. Thus, it is talented in extended applications. \n",
    "Here we will show an example of Neuroevolution Tasks using EvoX and Brax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install EvoX, skip it if you have already installed EvoX\n",
    "from importlib.util import find_spec\n",
    "\n",
    "if find_spec(\"evox\") is None:\n",
    "    %pip install evox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependent packages or functions in this example\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from evox.algorithms import PSO\n",
    "from evox.problems.neuroevolution.brax import BraxProblem\n",
    "from evox.utils import ParamsAndVector\n",
    "from evox.workflows import EvalMonitor, StdWorkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use EvoX to solve Neuroevolution Tasks\n",
    "Neuroevolution is an optimization method that combines neural networks with evolutionary algorithms to evolve the structure and parameters of neural networks. By simulating natural selection and genetic mechanisms, Neuroevolution aims to optimize neural network architectures and weights, addressing complex problems such as game AI, robotic control, and more.\n",
    "\n",
    "In our example of neuroevolution tasks, Brax is needed. So it is recommended to install Brax if you want to reproduce this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Brax\n",
    "\n",
    "Brax is a fast and fully differentiable physics engine used for research and development of robotics, human perception, materials science, reinforcement learning, and other simulation-heavy applications. \n",
    "\n",
    "For more information, you can browse the [Github of Brax](https://github.com/google/brax).\n",
    "\n",
    "We will demonstrate a \"hopper\" environment of Brax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a neural network class\n",
    "\n",
    "To start with, we need to decide which neural network we are about to construct.\n",
    "\n",
    "Here we will give a simple Convolutional Neural Network (CNN) class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an CNN using Torch.\n",
    "# This CNN has 2 layers.\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Linear(11, 4), nn.Tanh(), nn.Linear(4, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate a model\n",
    "\n",
    "Through the ``SimpleCNN`` class, we can initiate a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the model is on the same device, better to be on the GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Reset the random seed\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the total number of the model parameters, and check if the model id initialized correctly. If everything goes well, we will see the total number is 63."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of model parameters: 63\n"
     ]
    }
   ],
   "source": [
    "# Test if the model is initialized correctly by computing the number of model parameters\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of model parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test the dimoension of the inputs and outputs. If everything goes well, 11 inputs will obtain 3 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test model output: tensor([[-0.0559,  0.4188,  0.2301]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(1, 11, device=device)\n",
    "outputs = model(inputs)\n",
    "print(\"Test model output:\", outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we check the weights for this network, we will see that it's group of parameter sets, which EC algorithms cannot directly work with data in this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features.0.weight',\n",
       "              tensor([[-0.2840, -0.0592, -0.1448, -0.0804, -0.2664,  0.1210, -0.2703, -0.0192,\n",
       "                        0.1048, -0.1016,  0.1711],\n",
       "                      [ 0.0380,  0.1657,  0.1935, -0.1331,  0.1096, -0.1304,  0.0945, -0.1575,\n",
       "                        0.1395,  0.0610, -0.1180],\n",
       "                      [-0.1479,  0.0780,  0.2813,  0.1447, -0.0291, -0.0146,  0.1714, -0.2096,\n",
       "                        0.1002, -0.0999,  0.1744],\n",
       "                      [-0.1076,  0.0149,  0.1018,  0.2072, -0.0443,  0.2751, -0.2551, -0.0538,\n",
       "                       -0.3007,  0.0250,  0.0856]])),\n",
       "             ('features.0.bias', tensor([-0.1221,  0.1252, -0.0489, -0.2620])),\n",
       "             ('features.2.weight',\n",
       "              tensor([[ 0.3839,  0.3083,  0.2528,  0.3988],\n",
       "                      [ 0.1839,  0.2658,  0.4149, -0.1007],\n",
       "                      [-0.3900, -0.2459, -0.0667, -0.0549]])),\n",
       "             ('features.2.bias', tensor([-0.0034,  0.2865,  0.1604]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, EvoX provides some useful utilities to help us bridge the gap, and in this case, we have `ParamsAndVector` class to help us convert a tree-like struct into a vector and back.\n",
    "\n",
    "### Initiate an adapter\n",
    "\n",
    "An adapter can help us convert the data back-and-forth.\n",
    "\n",
    "- `to_vector` can convert a parameters dictionary to a vector.\n",
    "- `to_params` can convert a vector back to a parameters dictionary.\n",
    "\n",
    "There are also batched version conversion.\n",
    "\n",
    "- `batched_to_vector` can convert a batched parameters dictionary to a batch of vectors.\n",
    "- `batched_to_params` can convert a batch of vectors back to a batched parameters dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2840, -0.0592, -0.1448, -0.0804, -0.2664,  0.1210, -0.2703, -0.0192,\n",
       "         0.1048, -0.1016,  0.1711,  0.0380,  0.1657,  0.1935, -0.1331,  0.1096,\n",
       "        -0.1304,  0.0945, -0.1575,  0.1395,  0.0610, -0.1180, -0.1479,  0.0780,\n",
       "         0.2813,  0.1447, -0.0291, -0.0146,  0.1714, -0.2096,  0.1002, -0.0999,\n",
       "         0.1744, -0.1076,  0.0149,  0.1018,  0.2072, -0.0443,  0.2751, -0.2551,\n",
       "        -0.0538, -0.3007,  0.0250,  0.0856, -0.1221,  0.1252, -0.0489, -0.2620,\n",
       "         0.3839,  0.3083,  0.2528,  0.3988,  0.1839,  0.2658,  0.4149, -0.1007,\n",
       "        -0.3900, -0.2459, -0.0667, -0.0549, -0.0034,  0.2865,  0.1604])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter = ParamsAndVector(dummy_model=model)\n",
    "feature_weights = adapter.to_vector(model.state_dict())\n",
    "feature_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an adapter, we can set out to do this Neuroevolution Task like what we did in the Quick Start.\n",
    "\n",
    "## Set up the running process\n",
    "\n",
    "### Initiate an algorithm and a problem\n",
    "\n",
    "We still initiate a PSO algorithm, and the problem is a Brax problem in \"hopper\" environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the population size\n",
    "POP_SIZE = 10\n",
    "\n",
    "# Get the bound of the PSO algorithm\n",
    "model_params = dict(model.named_parameters())\n",
    "pop_center = adapter.to_vector(model_params)\n",
    "lower_bound = pop_center - 1\n",
    "upper_bound = pop_center + 1\n",
    "\n",
    "# Initialize the PSO, and you can also use any other algorithms\n",
    "algorithm = PSO(\n",
    "    pop_size=POP_SIZE,\n",
    "    lb=lower_bound,\n",
    "    ub=upper_bound,\n",
    "    device=device,\n",
    ")\n",
    "algorithm.setup()\n",
    "\n",
    "# Initialize the Brax problem\n",
    "problem = BraxProblem(\n",
    "    policy=model,\n",
    "    env_name=\"hopper\",\n",
    "    max_episode_length=1000,\n",
    "    num_episodes=3,\n",
    "    pop_size=POP_SIZE,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice:\n",
    "- `max_episode_length` is the maximum number of steps for each episode.\n",
    "\n",
    "- `num_episodes` is the number of episodes to run for each evaluation.\n",
    "\n",
    "In this case, we will be using 1000 steps for each episode, and the average reward of 3 episodes will be returned as the fitness value.\n",
    "\n",
    "### Set an monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalMonitor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set an monitor, and it can record the top 3 best fitnesses\n",
    "pop_monitor = EvalMonitor(\n",
    "    topk=3,\n",
    "    device=device,\n",
    ")\n",
    "pop_monitor.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate an workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an workflow\n",
    "workflow = StdWorkflow(opt_direction=\"max\")\n",
    "workflow.setup(\n",
    "    algorithm=algorithm,\n",
    "    problem=problem,\n",
    "    solution_transform=adapter,\n",
    "    monitor=pop_monitor,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the workflow\n",
    "\n",
    "Run the workflow and see the magic!\n",
    "\n",
    "```{note}\n",
    "The following block will take around 1 minute to run.\n",
    "The time may vary depending on your hardware.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generation 0:\n",
      "\tTime elapsed:  18.4627(s).\n",
      "\tTop fitness: tensor([-684.6812, -603.0337, -597.3137])\n",
      "\tBest params: {'features.0.weight': tensor([[-0.4586,  0.1369, -0.6505, -0.1045, -0.6985, -0.2686, -0.4071, -0.4004,\n",
      "          0.8730,  0.1611,  1.0660],\n",
      "        [ 0.9409,  0.3292, -0.2226,  0.4750,  0.0748,  0.6098, -0.1190,  0.7268,\n",
      "          0.2716, -0.1611, -0.7704],\n",
      "        [ 0.5922,  0.2081,  0.6272,  0.5489, -0.0808, -0.5174, -0.1271, -0.2541,\n",
      "          0.7212, -0.1730, -0.0791],\n",
      "        [-0.2435,  0.1791,  0.9000,  0.9618, -0.1028,  0.4076,  0.6518,  0.3856,\n",
      "         -0.4062,  0.6178,  0.5410]]), 'features.0.bias': tensor([-0.3906,  0.5298,  0.0304, -0.6333]), 'features.2.weight': tensor([[ 0.3054,  1.2495,  0.5532, -0.4268],\n",
      "        [ 0.8211,  0.4807,  0.9068, -0.0965],\n",
      "        [ 0.0078,  0.0530,  0.8113,  0.4728]]), 'features.2.bias': tensor([-0.4410,  0.8106,  0.1011])}\n",
      "In generation 1:\n",
      "\tTime elapsed:  5.4289(s).\n",
      "\tTop fitness: tensor([-684.6812, -658.5977, -611.5485])\n",
      "\tBest params: {'features.0.weight': tensor([[-0.4586,  0.1369, -0.6505, -0.1045, -0.6985, -0.2686, -0.4071, -0.4004,\n",
      "          0.8730,  0.1611,  1.0660],\n",
      "        [ 0.9409,  0.3292, -0.2226,  0.4750,  0.0748,  0.6098, -0.1190,  0.7268,\n",
      "          0.2716, -0.1611, -0.7704],\n",
      "        [ 0.5922,  0.2081,  0.6272,  0.5489, -0.0808, -0.5174, -0.1271, -0.2541,\n",
      "          0.7212, -0.1730, -0.0791],\n",
      "        [-0.2435,  0.1791,  0.9000,  0.9618, -0.1028,  0.4076,  0.6518,  0.3856,\n",
      "         -0.4062,  0.6178,  0.5410]]), 'features.0.bias': tensor([-0.3906,  0.5298,  0.0304, -0.6333]), 'features.2.weight': tensor([[ 0.3054,  1.2495,  0.5532, -0.4268],\n",
      "        [ 0.8211,  0.4807,  0.9068, -0.0965],\n",
      "        [ 0.0078,  0.0530,  0.8113,  0.4728]]), 'features.2.bias': tensor([-0.4410,  0.8106,  0.1011])}\n",
      "In generation 2:\n",
      "\tTime elapsed:  5.4241(s).\n",
      "\tTop fitness: tensor([-684.6812, -681.5258, -658.5977])\n",
      "\tBest params: {'features.0.weight': tensor([[-0.4586,  0.1369, -0.6505, -0.1045, -0.6985, -0.2686, -0.4071, -0.4004,\n",
      "          0.8730,  0.1611,  1.0660],\n",
      "        [ 0.9409,  0.3292, -0.2226,  0.4750,  0.0748,  0.6098, -0.1190,  0.7268,\n",
      "          0.2716, -0.1611, -0.7704],\n",
      "        [ 0.5922,  0.2081,  0.6272,  0.5489, -0.0808, -0.5174, -0.1271, -0.2541,\n",
      "          0.7212, -0.1730, -0.0791],\n",
      "        [-0.2435,  0.1791,  0.9000,  0.9618, -0.1028,  0.4076,  0.6518,  0.3856,\n",
      "         -0.4062,  0.6178,  0.5410]]), 'features.0.bias': tensor([-0.3906,  0.5298,  0.0304, -0.6333]), 'features.2.weight': tensor([[ 0.3054,  1.2495,  0.5532, -0.4268],\n",
      "        [ 0.8211,  0.4807,  0.9068, -0.0965],\n",
      "        [ 0.0078,  0.0530,  0.8113,  0.4728]]), 'features.2.bias': tensor([-0.4410,  0.8106,  0.1011])}\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum number of generations\n",
    "max_generation = 3\n",
    "\n",
    "# Run the workflow\n",
    "for index in range(max_generation):\n",
    "    print(f\"In generation {index}:\")\n",
    "    t = time.time()\n",
    "    workflow.step()\n",
    "    print(f\"\\tTime elapsed: {time.time() - t: .4f}(s).\")\n",
    "    monitor: EvalMonitor = workflow.get_submodule(\"monitor\")\n",
    "    print(f\"\\tTop fitness: {monitor.topk_fitness}\")\n",
    "    best_params = adapter.to_params(monitor.topk_solutions[0])\n",
    "    print(f\"\\tBest params: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The PSO wasn’t specialized for this type of tasks, so its performance limitations here are expected. Here we just show an example, and hope you can use a quantity of more effective algorithms in EvoX and enjoy your time!\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evoxtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
