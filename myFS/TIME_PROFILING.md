# 时间性能监控说明

## 📊 新增的时间打印功能

已在关键位置添加了详细的时间监控，帮助识别性能瓶颈。

### FS.evaluate() 的时间打印

```
[FS.evaluate] 开始评估，种群大小=200, 批次大小=256, use_cv=True, n_splits=5
[FS.evaluate] 数据传输耗时: 0.XXX秒  (仅在有数据传输时显示)
[FS.evaluate] 特征掩码计算耗时: 0.XXX秒
[FS.evaluate] 开始批处理，共X个批次
  [Batch 1/X] einsum=0.XXX秒, CV=X.XXX秒, 总计=X.XXX秒
    [CV Fold 1/5] 索引=0.XXX秒, 分割=0.XXX秒, 预测=0.XXX秒, 准确率=0.XXX秒, 总计=0.XXX秒
    [CV Fold 2/5] ...
    ...
    [CV 总结] 传输=0.XXX秒, 准备=0.XXX秒, 平均每fold=0.XXX秒, 求均值=0.XXX秒, CV总计=X.XXX秒
  [Batch 2/X] ...
[FS.evaluate] 结果合并耗时: 0.XXX秒
[FS.evaluate] 惩罚计算耗时: 0.XXX秒
[FS.evaluate] 评估总耗时: X.XXX秒
```

### 时间统计详解

#### 1. FS.evaluate 层级

| 步骤 | 说明 | 预期时间 |
|------|------|---------|
| **数据传输** | CPU→GPU数据传输 | 应该很短(<0.01s)，如果长说明有问题 |
| **特征掩码计算** | 应用阈值获取二值掩码 | 很短(<0.01s) |
| **批处理总计** | 所有批次的总时间 | 主要耗时部分 |
| **结果合并** | torch.cat合并所有批次结果 | 很短(<0.01s) |
| **惩罚计算** | 计算特征数量惩罚 | 很短(<0.01s) |

#### 2. 批次层级

| 步骤 | 说明 | 预期时间 |
|------|------|---------|
| **einsum** | Einstein求和应用特征掩码 | 短，取决于特征数 |
| **CV** | 交叉验证总时间 | 主要耗时！ |
| **快速评估** | 不使用CV时的评估 | 比CV快很多 |

#### 3. CV (交叉验证) 层级

| 步骤 | 说明 | 预期时间 |
|------|------|---------|
| **传输** | 数据设备检查和传输 | 应该为0 |
| **准备** | 生成随机索引和预分配tensor | 很短 |
| **索引** | 计算train/test索引 | 很短 |
| **分割** | 使用索引分割数据 | 短 |
| **预测** | KNN预测（cdist距离计算） | **主要耗时！** |
| **准确率** | 计算准确率 | 很短 |

## 🔍 性能瓶颈分析

### 正常情况
```
[FS.evaluate] 评估总耗时: 2.500秒
  - 数据传输: 0.001秒 (0.04%)  ✅
  - 特征掩码: 0.010秒 (0.4%)   ✅
  - Batch处理: 2.480秒 (99%)   
    - einsum: 0.050秒 (2%)     ✅
    - CV: 2.400秒 (96%)        ← 主要耗时
      - 预测: 2.000秒 (80%)    ← KNN距离计算
      - 其他: 0.400秒 (16%)    ✅
```

### 有问题的情况

#### 问题1: 数据传输慢
```
[FS.evaluate] 数据传输耗时: 0.500秒  ⚠️ 太慢！
```
**原因**: 数据在CPU上，需要传输到GPU
**解决**: 确保数据已在GPU上

#### 问题2: einsum慢
```
[Batch X/X] einsum=1.200秒  ⚠️ 太慢！
```
**原因**: 特征数太多或批次太大
**解决**: 减小batch_size或特征数

#### 问题3: CV传输慢
```
[CV 总结] 传输=0.500秒  ⚠️ 有CPU-GPU传输！
```
**原因**: 数据不在正确设备上
**解决**: 检查set_data()

## 📈 优化建议

### 根据时间分布优化

#### 如果 "预测" 占比>80%
这是正常的，因为KNN距离计算是主要计算。
- 可以减少n_splits (5→3)
- 或使用use_cv=False快速模式

#### 如果 "einsum" 占比>20%
说明特征掩码应用慢
- 减小batch_size
- 检查是否有不必要的内存拷贝

#### 如果 "数据传输" 出现且>0.01秒
说明有CPU-GPU传输
- 检查pop是否在GPU上
- 检查X, y是否在GPU上

#### 如果 "分割" 占比>10%
说明数据索引慢
- 可能数据量太大
- 检查是否使用了高级索引

## 🎯 使用示例

### 运行test.py查看详细时间
```bash
python test.py
```

输出示例:
```
处理数据集: 9_Tumors
数据集大小: 60 样本, 5726 特征, 9 类别

  Fold 1/10:
    训练集: 54 样本, 测试集: 6 样本
    [FS.evaluate] 开始评估，种群大小=200, 批次大小=256, use_cv=True, n_splits=5
    [FS.evaluate] 特征掩码计算耗时: 0.008秒
    [FS.evaluate] 开始批处理，共1个批次
      [Batch 1/1] einsum=0.045秒, CV=2.341秒, 总计=2.386秒
        [CV Fold 1/5] 索引=0.001秒, 分割=0.023秒, 预测=0.421秒, 准确率=0.002秒, 总计=0.447秒
        [CV Fold 2/5] 索引=0.001秒, 分割=0.022秒, 预测=0.419秒, 准确率=0.002秒, 总计=0.444秒
        ...
        [CV 总结] 传输=0.000秒, 准备=0.003秒, 平均每fold=0.446秒, 求均值=0.001秒, CV总计=2.341秒
    [FS.evaluate] 结果合并耗时: 0.001秒
    [FS.evaluate] 惩罚计算耗时: 0.002秒
    [FS.evaluate] 评估总耗时: 2.397秒
```

### 分析输出

从上面的输出可以看出：
1. ✅ 无数据传输 (传输=0.000秒)
2. ✅ einsum很快 (0.045秒)
3. ⚠️ CV很慢 (2.341秒) - 这是正常的，因为5折CV
4. ✅ 每fold的预测是主要耗时 (0.42秒/fold)
5. ✅ 其他操作都很快

**结论**: 性能瓶颈在KNN预测，这是正常的。可以通过减少n_splits来加速。

## 💡 快速优化方案

### 方案1: 减少交叉验证折数
在`FS.py`中修改：
```python
def evaluate(self, pop, batch_size=512, use_cv=True, n_splits=3):
                                                              ^^^
```
预期加速: 1.6倍

### 方案2: 使用快速模式
在`FS.py`中修改：
```python
def evaluate(self, pop, batch_size=512, use_cv=False):
                                                ^^^^^
```
预期加速: 4-5倍（但可能过拟合）

### 方案3: 增大批次大小
```python
def evaluate(self, pop, batch_size=512, ...):
                                   ^^^
```
预期加速: 1.2-1.5倍

## 📞 故障排查

### Q: 看到很多数据传输时间
A: 数据不在GPU上，检查:
```python
print(f"X在GPU: {problem.X.is_cuda}")
print(f"y在GPU: {problem.y.is_cuda}")
print(f"pop在GPU: {pop.is_cuda}")
```

### Q: einsum特别慢
A: 特征太多或批次太大，尝试:
```python
# 减小批次
batch_size=128  # 原来256或512

# 或检查特征数
print(f"特征数: {problem.n_features}")
```

### Q: 预测时间不稳定
A: 可能是GPU未预热，前几次会慢，后面会稳定

### Q: 总时间还是很长
A: 这是正常的，因为:
- 5折CV = 5倍计算量
- KNN距离计算本身就慢
- 尝试上面的优化方案
